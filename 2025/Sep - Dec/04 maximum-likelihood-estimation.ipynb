{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70895699",
   "metadata": {},
   "source": [
    "# **Maximum Likelihood Estimation**\n",
    "\n",
    "#### **The way to know the parameters of your model**\n",
    "\n",
    "When fitting real-world data into a model, one of the most crucial actions is estimating its parameters. Maximum Likelihood Estimation (MLE) provides powerful, general and theoretically sound estimators with reliable uncertainty estimates. It covers from linear regression up to more complex models. In this guide I will not only explain how it works, but also some usual scenerios were you would *likely* use it through Python examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5976d6",
   "metadata": {},
   "source": [
    "## **1. How Does The Method Work?**\n",
    "\n",
    "We will start by covering how MLE works, from intuition to calculation. For instance, imagine you are analyzing the height of a sample of people and you suspect it is generated by a normal distribution, but you do not know its respective parameters $\\theta=(\\mu, \\sigma)$, where $\\mu$ is the mean and $\\sigma$ is the standard deviation.\n",
    "\n",
    "### **1.1. Mathematical Explanation**\n",
    "\n",
    "The \"likelihood\" is the probability of observing your actual data, assuming specific values for the parameters within $\\theta$.\n",
    "\n",
    "#### **Step 1: Assume a Model**\n",
    "\n",
    "Because of what I said previously, you have supposed the heights come from a normal distribution and you would like to *estimate* $\\mu$ and $\\sigma$.\n",
    "\n",
    "#### **Step 2: Write the Likelihood Function**\n",
    "\n",
    "- For a single data point (person in the current example), $x_1$, from a normal distribution, this is just the value of the probability density function (PDF) (or probability mass function (PMF) in case of a discrete random variable): $P_{\\theta}(x_1)$\n",
    "\n",
    "- For the entire sample, $x_1,\\dots,x_n$, the likelihood function $L_\\theta$ is the joint probability of observing all your data points. If we assume the observations are independent (e.g. the height of a child it is not influenced by the height of its parents), this is the product of the individual probabilities:\n",
    "\n",
    "$$L_\\theta(x_1,\\dots,x_n)=P_{\\theta}(x_1)\\times\\cdots\\times P_{\\theta}(x_n)$$\n",
    "\n",
    "It is important to note that **$L_\\theta$ is a function of the parameters** ($\\theta=(\\mu,\\sigma)$ from the example), not the data ($x_1,\\dots,x_n$).\n",
    "\n",
    "#### **Step 3: The \"Maximum\" Part - Find the Peak**\n",
    "\n",
    "Now, you ask: \"For which values of $\\mu$ and $\\sigma$ is this likelihood function $L_\\theta$ the largest?\". We find this maximum mathematically. Because products can be messy, we almost always work with the **Log-Likelihood** function. Since log is a monotonically increasing function, maximizing the log-likelihood is equivalent to maximizing the likelihood. Taking the log turns the product into a sum, which is much easier to differentiate:\n",
    "\n",
    "$$\\ln(L_\\theta(x_1,\\dots,x_n))=\\ln(P_{\\theta}(x_1))+\\cdots+\\ln(P_{\\theta}(x_n))$$\n",
    "\n",
    "#### **Step 4: Use Calculus to Find the Maximum**\n",
    "\n",
    "To find the maximum of a function, we take its derivative with respect to the parameters, set it to zero and solve. In our example, we would need:\n",
    "$$\\frac{\\partial\\ln L_\\theta}{\\partial\\mu}=0,\\quad \\frac{\\partial\\ln L_\\theta}{\\partial\\sigma}=0.$$\n",
    "\n",
    "In this case, the values of $\\mu$ and $\\sigma$ that satisfy these equations are the **Maximum Likelihood Estimates (MLE's)**, often denoted $\\hat{\\mu}_{MLE}$ and $\\hat{\\sigma}_{MLE}$, or simply $\\hat{\\mu}$ and $\\hat{\\sigma}$.\n",
    "\n",
    "When the size of the sample, $n$, is large or $P_\\theta$ has a complex form, we usually use software like Python or R for the MLE's. We will come back to this example later.\n",
    "\n",
    "### **1.2. A Toy Example**\n",
    "\n",
    "Now imagine you flip a coin 10 times and get 7 heads and 3 tails. You want to estimate the probability of getting heads: $p$.\n",
    "\n",
    "1. **Assume a Model:** We assume the data is generated by a Bernoulli distribution of parameter $\\theta=p$.\n",
    "\n",
    "2. **Write the Likelihood Function:** The probability of getting a head given $p$ is $P_p(x)=p$, while the probability of getting a tail is $P_p(x)=1-p$. Thus, the likelihood function is\n",
    "$$L_p(x_1,\\dots,x_{10})=p^7(1-p)^3$$\n",
    "\n",
    "3. **Find the Maximum:** The log of $L$ in this case is\n",
    "$$\\ln L_p(x_1,\\dots,x_{10})=7\\ln p + 3\\ln (1-p)$$\n",
    "\n",
    "4. **Use Calculus to Find the Maximum:** By differentiating, we obtain\n",
    "$$\\frac{\\partial\\ln L_p}{\\partial p}=\\frac{7}{p}-\\frac{3}{1-p}=0\\iff\\frac{7}{p}=\\frac{3}{1-p}=0\\iff 7(1-p)=3p\\iff 10p=7\\iff p=0.7$$\n",
    "\n",
    "Thus, the Maximum Likelihood Estimate for the probability of heads is $\\hat{p}=0.7$. This makes perfect intuitive sense! The most likely coin, given 7 heads in 10 flips, is one that is biased to land on heads 70% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4f7214",
   "metadata": {},
   "source": [
    "## **2. Building Models in Python**\n",
    "\n",
    "As I stated, MLE is not a model itself; it's an estimation method for the parameters of a model. Applying when you have already decided on the structure of your model based on your data analysis is the most common case.\n",
    "\n",
    "### **2.1. Normal Distribution**\n",
    "\n",
    "Returning to the example of heights, you have the following dataset of 500 (independent) people:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e91db68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01ede9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    180.450712\n",
       "1    170.926035\n",
       "2    182.715328\n",
       "3    195.845448\n",
       "4    169.487699\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating the height dataset\n",
    "mean = 173\n",
    "std = 15\n",
    "size = 500\n",
    "\n",
    "np.random.seed(42) # control randomness\n",
    "heights = np.random.normal(mean, std, size)\n",
    "\n",
    "ser = pd.Series(data=heights)\n",
    "ser.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eb028c",
   "metadata": {},
   "source": [
    "As you might note, the dataset has been created from random numbers following a normal distrution with $\\mu=173$ and $\\sigma=15$, both units in centimeters. However, as a data analyst, you will not usually know the parameters and will have to estimate them. The first insight of normal distribution usually comes from observing the histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bac55996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Count')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.subplots()[1]\n",
    "ser.hist(bins=30, ax=ax)\n",
    "ax.set_xlabel('Height (centimeters)')\n",
    "ax.set_ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5e36f8",
   "metadata": {},
   "source": [
    "Actually, the sample mean and the sample standard deviation (with $n-1$ degrees of freedom) are good (and unbiased) estimators for the population mean and population standard deviation, respectively. With `pandas`'s function `describe`, it can be done in a single line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aae99207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean    173.102570\n",
       "std      14.718799\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser.describe()[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c291d3b",
   "metadata": {},
   "source": [
    "As we can see, the sample mean is close to the actual value (173), the same for the sample standard deviation (15). Despite all, it is still a good example to explain MLE is usually done through the Python library `scipy`. There are two different approaches we will explain.\n",
    "\n",
    "#### **An implicit approach**\n",
    "As it name suggests, we do not construct the log-likelihood function at any time. You will likely use this approach when studying well-know distributions such as the normal one. `scipy.stats` offers this functionality through `fit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493c40c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(173.10256991882972), np.float64(14.704072544949403))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# implicit approach\n",
    "data = ser.values   # the values from the sample\n",
    "mu_mle, sigma_mle = stats.norm.fit(data)\n",
    "mu_mle, sigma_mle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77413c8c",
   "metadata": {},
   "source": [
    "As we can see, $\\hat{\\mu}_{MLE},\\,\\hat{\\sigma}_{MLE}$ are practically the same values as the sample mean and the sample standard deviation. Additionally, we have used `norm` to specify we want to fit a model generated by a normal distribution. You can check [scipy.stats](https://docs.scipy.org/doc/scipy/reference/stats.html#probability-distributions) for all the probability distributions it includes (binomial, exponential, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a130b30d",
   "metadata": {},
   "source": [
    "#### **An explicit approach**\n",
    "When the probability distribution gets more complex, we have no other choice than to construct the log-likelihood function $\\ln L$ on Python explicitly. It usually requires some mathematical manipulation. In our example, since we suspect heigths are generated by a normal distribution with unknown parameters $\\theta=(\\mu, \\sigma)$, the PDF for an observation $x_i$ is\n",
    "\n",
    "$$P_\\theta(x_i)=\\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\left( -\\frac{1}{2}\\left(\\frac{x_i-\\mu}{\\sigma}\\right)^{\\!2}\\,\\right).$$\n",
    "\n",
    "Again, by assuming the observations are independent, we get\n",
    "\n",
    "$$L_\\theta(x_1,\\dots,x_{500})=\\prod_{i=1}^{500}\\frac{1}{\\sigma\\sqrt{2\\pi}}\\exp\\left( -\\frac{1}{2}\\left(\\frac{x_i-\\mu}{\\sigma}\\right)^{\\!2}\\,\\right)=\\left(\\frac{1}{2\\pi\\sigma^2}\\right)^{500/2}\\prod_{i=1}^{500}\\exp\\left( -\\frac{1}{2}\\left(\\frac{x_i-\\mu}{\\sigma}\\right)^{\\!2}\\,\\right).$$\n",
    "\n",
    "Taking the logarithm, we obtain\n",
    "\n",
    "$$\\ln(L_\\theta(x_1,\\dots,x_{500})) = -\\frac{500}{2}\\ln(2\\pi) - \\frac{500}{2}\\ln(\\sigma^2) - \\frac{1}{2\\sigma^2} \\sum_{i=1}^{500} (x_i - \\mu)^2.$$\n",
    "\n",
    "Since $-(500/2)\\ln(2\\pi)$ is a constant term, maximizing $\\ln L_\\theta$ is equivalent to maximizing\n",
    "\n",
    "$$l_\\theta(x_1,\\dots,x_{500})=-\\left(\\frac{500}{2}\\ln(\\sigma^2) + \\frac{1}{2\\sigma^2} \\sum_{i=1}^{500} (x_i - \\mu)^2\\right).$$\n",
    "\n",
    "We usually call *objective function* to the function we want to maximize or minimize depending on the context. In this case, $l_\\theta$ is the objective function we want to maximize. However, `scipy.optimize` only has a `minimize` function. This means it will minimize $l_\\theta$ instead of maximizing. Since maximizing a (scalar) function $f$ is equivalent to minimizing $-f$, we will consider $-l_\\theta$ the objective function to minimize within the example. Now we are able to able define it on Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fce68da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the objective function for 500 observations\n",
    "def objective_function1 (params, data):\n",
    "    '''params contains the parameters we want to estimate,\n",
    "    while data is the sample of 500 observations'''\n",
    "\n",
    "    if not len(data) == 500:\n",
    "        raise TypeError('data must be a 500-element array.')\n",
    "\n",
    "    mu_mle, sigma_mle = params\n",
    "    addend1 = 500/2*np.log(sigma_mle**2)\n",
    "    addend2 = 1/(2*sigma_mle**2)*np.sum((data-mu_mle)**2)\n",
    "    return addend1 + addend2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93599573",
   "metadata": {},
   "source": [
    "Note the number of height observations to introduce within `objective_function1` must be 500, otherwise the objective function would be defined wrongly. For an arbitrary number of observations $n$ we can definite in this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3a7e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the objective function for n observations\n",
    "def objective_function2 (params, data):\n",
    "    '''params contains the parameters we want to estimate,\n",
    "    while data is a sample of n observations'''\n",
    "\n",
    "    mu_mle, sigma_mle = params\n",
    "    n = len(data)\n",
    "    addend1 = n/2*np.log(sigma_mle**2)\n",
    "    addend2 = 1/(2*sigma_mle**2)*np.sum((data-mu_mle)**2)\n",
    "    return addend1 + addend2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d545a652",
   "metadata": {},
   "source": [
    "As long as `len(data)` is equal to 500, both objective functions are equivalent. But, in practice, the latter is highly preferred. Now we can compute the MLE's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cfd03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([173.10257136,  14.70407173])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ser.values\n",
    "x_0 = [173.0, 15.0]\n",
    "estimations = minimize(objective_function1, x_0, args=(data,))\n",
    "estimations.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475d0674",
   "metadata": {},
   "source": [
    "As you can note, they are practically the same as the ones from the implicit approach.\n",
    "\n",
    "### **2.2. Linear Regression**\n",
    "Simple linear regression is popular because it is a straightforward, interpretable and efficient method for understanding and predicting relationships between two variables variables: $x_i$ and $y_i$ for any observation $i$. It is assumed they are related linearly:\n",
    "$$ y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i\\,\\text{ where }\\epsilon_i\\sim\\mathcal{N}(\\mu,\\sigma)\\text{ (normally distributed errors)}.$$\n",
    "\n",
    "In order to estimate the parameters $\\beta_0$ and $\\beta_1$, Ordinary Least Squares (OLS) is the common method. But OLS turns out to be mathematically equivalent to MLE if you assume the errors are normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2978403",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
